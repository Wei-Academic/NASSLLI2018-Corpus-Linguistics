{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Day 4: More NLTK and Corpus Tools\n",
    "\n",
    "Na-Rae Han (`naraehan@pitt.edu`) and David J. Birnbaum (`djbpitt@pitt.edu`) \n",
    "\n",
    "June 25-29, [NASSLLI 2018 at CMU](https://www.cmu.edu/nasslli2018/) \n",
    "\n",
    "This tutorial is found on https://github.com/naraehan/NASSLLI2018-Corpus-Linguistics. \n",
    "- Jump to: [Day 1](day1.ipynb), [Day 2](day2.ipynb), [Day 3](day3.ipynb), [Day 4](day4.ipynb), [Day 5](day5.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "- Import NLTK\n",
    "- Load up the Inaugural corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "corpus_root = 'C:/Users/narae/Desktop/inaugural'  # Use your own userid; Mac users should omit C:\n",
    "inaug = PlaintextCorpusReader(corpus_root, '.*txt')  # all files ending in 'txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pprint\n",
    "inaug.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inaug.words()[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chom = 'colorless green ideas sleep furiously'.split()\n",
    "chom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.bigrams(chom)\n",
    "# fundtion returns a \"generator\" object: it is memory-efficient but won't let us take a peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator object works well in a loop environment\n",
    "for x in nltk.bigrams(chom):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force it into a list type\n",
    "list(nltk.bigrams(chom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigram function also available\n",
    "list(nltk.trigrams(chom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's build a bigram list of the entire inaugural corpus\n",
    "inaug_bigrams = list(nltk.bigrams(inaug.words()))\n",
    "inaug_bigrams[:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last 10 bigrams\n",
    "inaug_bigrams[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the most frquent bigrams? \n",
    "inaug_bigrams_fd = nltk.FreqDist(inaug_bigrams)\n",
    "inaug_bigrams_fd.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inaug_bigrams_fd[('of', 'the')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What functions are available with this object? \n",
    "dir(inaug_bigrams_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# over 1% of all bigrams are 'of the'! \n",
    "inaug_bigrams_fd.freq(('of', 'the'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional frequency distribution: by preceding word\n",
    "- What are the most common words following 'shall'? \n",
    "  - 'shall' becomes the condition for the next word: conditional frequency distribution. \n",
    "  - Stats can be compiled from a list of bigrams (w1, w2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cfd is built from bigrams: a list of (w1, w2) \n",
    "inaug_bigrams_cfd = nltk.ConditionalFreqDist(inaug_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'shall' as the w1 condition. Value is a FreqDist! \n",
    "inaug_bigrams_cfd['shall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inaug_bigrams_cfd['shall']['not']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total count of 'shall'\n",
    "inaug_bigrams_cfd['shall'].N()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# likelihood of 'not' following 'shall' \n",
    "inaug_bigrams_cfd['shall'].freq('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inaug_bigrams_cfd['shall'].most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional frequency distribution: count per year\n",
    "- Are words such as 'freedom', 'liberty', 'god' more frequent or less over time? \n",
    "- We will try out NLTK's book chapter on the Inaugural corpus: http://www.nltk.org/book/ch02.html#inaugural-address-corpus\n",
    "\n",
    "**Plotting/visualization**\n",
    "- If plotting breaks on you, matplotlib is not installed. Install it via `!pip install matplotlib`. \n",
    "- If plot graphs are too small, you can:\n",
    "```\n",
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(20,10))\n",
    "cfd.plot()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nltk.Text object and other corpus tools\n",
    "- NLTK's Text object class provides a concordancer and other classic corpus tools\n",
    "- A Text object can be built from a token list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inaug_Text = nltk.Text(inaug.words())\n",
    "inaug_Text.concordance(\"shall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(inaug_Text.concordance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What other handy functions are available? \n",
    "dir(inaug_Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collocations found in this corpus\n",
    "inaug_Text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More info on the method. Doesn't say what stats are used...\n",
    "help(inaug_Text.collocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common context (surrounding words) shared by a list of words\n",
    "inaug_Text.common_contexts(['shall', 'will'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More tomorrow\n",
    "\n",
    "- Advanced processing: lemmatization, POS tagging\n",
    "- Bring your own corpus: We will try on 1-2 corpora from your suggestions\n",
    "\n",
    "Last meeting on [Day 5 (Friday)](day5.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
