{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Day 4: More NLTK and Corpus Tools\n",
    "\n",
    "Na-Rae Han (`naraehan@pitt.edu`) and David J. Birnbaum (`djbpitt@pitt.edu`) \n",
    "\n",
    "June 25-29, [NASSLLI 2018 at CMU](https://www.cmu.edu/nasslli2018/) \n",
    "\n",
    "This tutorial is found on https://github.com/naraehan/NASSLLI2018-Corpus-Linguistics. \n",
    "- Jump to: [Day 1](day1.ipynb), [Day 2](day2.ipynb), [Day 3](day3.ipynb), [Day 4](day4.ipynb), [Day 5](day5.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "- Import NLTK\n",
    "- Load up the Inaugural corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "corpus_root = 'C:/Users/narae/Desktop/inaugural'  # Use your own userid; Mac users should omit C:\n",
    "inaug = PlaintextCorpusReader(corpus_root, '.*txt')  # all files ending in 'txt' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1789-Washington.txt', '1793-Washington.txt', '1797-Adams.txt', '1801-Jefferson.txt', '1805-Jefferson.txt', '1809-Madison.txt', '1813-Madison.txt', '1817-Monroe.txt', '1821-Monroe.txt', '1825-Adams.txt', '1829-Jackson.txt', '1833-Jackson.txt', '1837-VanBuren.txt', '1841-Harrison.txt', '1845-Polk.txt', '1849-Taylor.txt', '1853-Pierce.txt', '1857-Buchanan.txt', '1861-Lincoln.txt', '1865-Lincoln.txt', '1869-Grant.txt', '1873-Grant.txt', '1877-Hayes.txt', '1881-Garfield.txt', '1885-Cleveland.txt', '1889-Harrison.txt', '1893-Cleveland.txt', '1897-McKinley.txt', '1901-McKinley.txt', '1905-Roosevelt.txt', '1909-Taft.txt', '1913-Wilson.txt', '1917-Wilson.txt', '1921-Harding.txt', '1925-Coolidge.txt', '1929-Hoover.txt', '1933-Roosevelt.txt', '1937-Roosevelt.txt', '1941-Roosevelt.txt', '1945-Roosevelt.txt', '1949-Truman.txt', '1953-Eisenhower.txt', '1957-Eisenhower.txt', '1961-Kennedy.txt', '1965-Johnson.txt', '1969-Nixon.txt', '1973-Nixon.txt', '1977-Carter.txt', '1981-Reagan.txt', '1985-Reagan.txt', '1989-Bush.txt', '1993-Clinton.txt', '1997-Clinton.txt', '2001-Bush.txt', '2005-Bush.txt', '2009-Obama.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pprint\n",
    "inaug.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fellow', '-', 'Citizens', 'of', 'the', 'Senate', 'and', 'of', 'the', 'House', 'of', 'Representatives', ':', 'Among', 'the', 'vicissitudes', 'incident', 'to', 'life', 'no', 'event', 'could', 'have', 'filled', 'me', 'with', 'greater', 'anxieties', 'than', 'that', 'of', 'which', 'the', 'notification', 'was', 'transmitted', 'by', 'your', 'order', ',', 'and', 'received', 'on', 'the', '14th', 'day', 'of', 'the', 'present', 'month']\n"
     ]
    }
   ],
   "source": [
    "print(inaug.words()[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['colorless', 'green', 'ideas', 'sleep', 'furiously']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chom = 'colorless green ideas sleep furiously'.split()\n",
    "chom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object bigrams at 0x0000025345E0EF10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.bigrams(chom)\n",
    "# fundtion returns a \"generator\" object: it is memory-efficient but won't let us take a peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('colorless', 'green')\n",
      "('green', 'ideas')\n",
      "('ideas', 'sleep')\n",
      "('sleep', 'furiously')\n"
     ]
    }
   ],
   "source": [
    "# generator object works well in a loop environment\n",
    "for x in nltk.bigrams(chom):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('colorless', 'green'), ('green', 'ideas'), ('ideas', 'sleep'), ('sleep', 'furiously')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Force it into a list type\n",
    "list(nltk.bigrams(chom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('colorless', 'green', 'ideas'), ('green', 'ideas', 'sleep'), ('ideas', 'sleep', 'furiously')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trigram function also available\n",
    "list(nltk.trigrams(chom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Fellow', '-'), ('-', 'Citizens'), ('Citizens', 'of'), ('of', 'the'), ('the', 'Senate'), ('Senate', 'and'), ('and', 'of'), ('of', 'the'), ('the', 'House'), ('House', 'of')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's build a bigram list of the entire inaugural corpus\n",
    "inaug_bigrams = list(nltk.bigrams(inaug.words()))\n",
    "inaug_bigrams[:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('you', '.'), ('.', 'And'), ('And', 'God'), ('God', 'bless'), ('bless', 'the'), ('the', 'United'), ('United', 'States'), ('States', 'of'), ('of', 'America'), ('America', '.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last 10 bigrams\n",
    "inaug_bigrams[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('of', 'the'), 1754), ((',', 'and'), 1278), (('in', 'the'), 746), (('to', 'the'), 689), (('of', 'our'), 596), (('.', 'The'), 581), (('.', 'We'), 468), (('and', 'the'), 452), ((',', 'the'), 365), (('.', 'It'), 343), ((',', 'but'), 314), (('to', 'be'), 305), (('by', 'the'), 305), (('for', 'the'), 290), ((',', 'we'), 263), (('of', 'a'), 252), (('the', 'people'), 243), (('.', 'I'), 226), (('with', 'the'), 220), (('the', 'world'), 215), ((',', 'to'), 212), (('that', 'the'), 210), ((\"'\", 's'), 202), (('.', 'In'), 202), (('have', 'been'), 201), ((',', 'in'), 200), ((',', 'I'), 188), (('will', 'be'), 182), (('has', 'been'), 178), (('is', 'the'), 176)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the most frquent bigrams? \n",
    "inaug_bigrams_fd = nltk.FreqDist(inaug_bigrams)\n",
    "inaug_bigrams_fd.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1754"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaug_bigrams_fd[('of', 'the')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'N', 'Nr', '_N', '__add__', '__and__', '__class__', '__contains__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__iand__', '__init__', '__ior__', '__isub__', '__iter__', '__le__', '__len__', '__lt__', '__missing__', '__module__', '__ne__', '__neg__', '__new__', '__or__', '__pos__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__sub__', '__subclasshook__', '__unicode__', '__weakref__', '_cumulative_frequencies', '_keep_positive', 'clear', 'copy', 'elements', 'freq', 'fromkeys', 'get', 'hapaxes', 'items', 'keys', 'max', 'most_common', 'pformat', 'plot', 'pop', 'popitem', 'pprint', 'r_Nr', 'setdefault', 'subtract', 'tabulate', 'unicode_repr', 'update', 'values']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What functions are available with this object? \n",
    "dir(inaug_bigrams_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012039096175493506"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# over 1% of all bigrams are 'of the'! \n",
    "inaug_bigrams_fd.freq(('of', 'the'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional frequency distribution: by preceding word\n",
    "- What are the most common words following 'shall'? \n",
    "  - 'shall' becomes the condition for the next word: conditional frequency distribution. \n",
    "  - Stats can be compiled from a list of bigrams (w1, w2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cfd is built from bigrams: a list of (w1, w2) \n",
    "inaug_bigrams_cfd = nltk.ConditionalFreqDist(inaug_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'be': 64, 'not': 19, 'have': 16, 'endeavor': 8, 'strive': 5, 'make': 5, 'do': 5, 'never': 5, 'continue': 4, 'we': 4, ...})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'shall' as the w1 condition. Value is a FreqDist! \n",
    "inaug_bigrams_cfd['shall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaug_bigrams_cfd['shall']['not']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total count of 'shall'\n",
    "inaug_bigrams_cfd['shall'].N()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06129032258064516"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# likelihood of 'not' following 'shall' \n",
    "inaug_bigrams_cfd['shall'].freq('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 64), ('not', 19), ('have', 16), ('endeavor', 8), ('strive', 5), ('make', 5), ('do', 5), ('never', 5), ('continue', 4), ('we', 4)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaug_bigrams_cfd['shall'].most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional frequency distribution: count per year\n",
    "- Are words such as 'freedom', 'liberty', 'god' more frequent or less over time? \n",
    "- We will try out NLTK's book chapter on the Inaugural corpus: http://www.nltk.org/book/ch02.html#inaugural-address-corpus\n",
    "\n",
    "**Plotting/visualization**\n",
    "- If plotting breaks on you, matplotlib is not installed. Install it via `!pip install matplotlib`. \n",
    "- If plot graphs are too small, you can:\n",
    "```\n",
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(20,10))\n",
    "cfd.plot()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nltk.Text object and other corpus tools\n",
    "- NLTK's Text object class provides a concordancer and other classic corpus tools\n",
    "- A Text object can be built from a token list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 314 matches:\n",
      "ur consideration such measures as he shall judge necessary and expedient .\" The\n",
      "ived from official opportunities , I shall again give way to my entire confiden\n",
      "ccasion which brings us together , I shall take my present leave ; but not with\n",
      "te . When the occasion proper for it shall arrive , I shall endeavor to express\n",
      "asion proper for it shall arrive , I shall endeavor to express the high sense I\n",
      " , and in your presence : That if it shall be found during my administration of\n",
      "determination to support it until it shall be altered by the judgments and wish\n",
      "es and the public opinion , until it shall be otherwise ordained by Congress ; \n",
      "gree to comply with your wishes , it shall be my strenuous endeavor that this s\n",
      "gacious injunction of the two Houses shall not be without effect . With this gr\n",
      "ities provided by our Constitution I shall find resources of wisdom , of virtue\n",
      "a wise and frugal Government , which shall restrain men from injuring one anoth\n",
      "rain men from injuring one another , shall leave them otherwise free to regulat\n",
      "ts of industry and improvement , and shall not take from the mouth of labor the\n",
      "l administration of your affairs . I shall often go wrong through defect of jud\n",
      " defect of judgment . When right , I shall often be thought wrong by those whos\n",
      "ts , it will replace the advances we shall have made . I know that the acquisit\n",
      " the benefit of all its strength . I shall now enter on the duties to which my \n",
      " citizens have again called me , and shall proceed in the spirit of those princ\n",
      "imes injurious to your interests . I shall need , therefore , all the indulgenc\n",
      "not lessen with increasing years . I shall need , too , the favor of that Being\n",
      "eir measures that whatsoever they do shall result in your good , and shall secu\n",
      "y do shall result in your good , and shall secure to you the peace , friendship\n",
      "he intercourse between the States we shall add much to the convenience and comf\n",
      ", what is of greater importance , we shall shorten distances , and , by making \n"
     ]
    }
   ],
   "source": [
    "inaug_Text = nltk.Text(inaug.words())\n",
    "inaug_Text.concordance(\"shall\")\n",
    "# try \"women\", \"men\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method concordance in module nltk.text:\n",
      "\n",
      "concordance(word, width=79, lines=25) method of nltk.text.Text instance\n",
      "    Print a concordance for ``word`` with the specified context window.\n",
      "    Word matching is not case-sensitive.\n",
      "    :seealso: ``ConcordanceIndex``\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(inaug_Text.concordance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_CONTEXT_RE', '_COPY_TOKENS', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', '__weakref__', '_concordance_index', '_context', 'collocations', 'common_contexts', 'concordance', 'count', 'dispersion_plot', 'findall', 'generate', 'index', 'name', 'plot', 'readability', 'similar', 'tokens', 'unicode_repr', 'vocab']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What other handy functions are available? \n",
    "dir(inaug_Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; four years; years ago; Federal\n",
      "Government; General Government; American people; Vice President; Old\n",
      "World; Almighty God; Fellow citizens; Chief Magistrate; Chief Justice;\n",
      "God bless; every citizen; Indian tribes; public debt; one another;\n",
      "foreign nations; political parties\n"
     ]
    }
   ],
   "source": [
    "# Collocations found in this corpus. Try window size of 3. \n",
    "inaug_Text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method collocations in module nltk.text:\n",
      "\n",
      "collocations(num=20, window_size=2) method of nltk.text.Text instance\n",
      "    Print collocations derived from the text, ignoring stopwords.\n",
      "    \n",
      "    :seealso: find_collocations\n",
      "    :param num: The maximum number of collocations to print.\n",
      "    :type num: int\n",
      "    :param window_size: The number of tokens spanned by a collocation (default=2)\n",
      "    :type window_size: int\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# More info on the method. Doesn't say what stats are used...\n",
    "help(inaug_Text.collocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we_always ,_we i_not i_to which_secure ?_we we_have as_prevent\n",
      "we_stand i_ask this_be ,_make they_not government_be we_be there_be\n",
      "we_not we_give future_be ,_always\n"
     ]
    }
   ],
   "source": [
    "# common context (surrounding words) shared by a list of words\n",
    "inaug_Text.common_contexts(['shall', 'will'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More tomorrow\n",
    "\n",
    "- Advanced processing: lemmatization, POS tagging\n",
    "- Bring your own corpus: We will try on 1-2 corpora from your suggestions\n",
    "\n",
    "Last meeting on [Day 5 (Friday)](day5.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
